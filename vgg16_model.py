# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19q8ceO0BZVR4ynQZxEr7XTkAwxAMozkR
"""

from google.colab import files
import zipfile
import os

# Upload zip file
uploaded = files.upload()

# Extract zip file
zip_path = list(uploaded.keys())[0]
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/dataset")

# Path to dataset folder
data_dir = "/content/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone"

# Verify classes
print(os.listdir(data_dir))

import zipfile
import os

zip_path = "/content/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone.zip"

# Extract
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/dataset")

# Check extracted folders
print(os.listdir("/content/dataset"))

data_dir = "/content/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone"

import os
print(os.listdir(data_dir))

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

print("TensorFlow version:", tf.__version__)
print("GPU Available:", tf.config.list_physical_devices('GPU'))

# ===============================
# 1. MOUNT GOOGLE DRIVE & SET PATHS
# ===============================

# Set your dataset path based on the file structure shown
dataset_path = '/content/dataset/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'

# Verify the path and classes
classes = ['Cyst', 'Normal', 'Stone', 'Tumor']
for class_name in classes:
    class_path = os.path.join(dataset_path, class_name)
    if os.path.exists(class_path):
        num_images = len(os.listdir(class_path))
        print(f"{class_name}: {num_images} images")
    else:
        print(f"Warning: {class_name} folder not found!")

# ===============================
# 2. HYPERPARAMETERS
# ===============================
IMG_SIZE = (224, 224)  # VGG16 input size
BATCH_SIZE = 32
EPOCHS = 25
LEARNING_RATE = 0.001
NUM_CLASSES = 4

# ===============================
# 3. DATA PREPROCESSING & AUGMENTATION
# ===============================
# Data augmentation for training (helps prevent overfitting)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.2  # 80% train, 20% validation
)

# Only rescaling for validation data
val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Create data generators
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

validation_generator = val_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=False,
    seed=42
)

# Display class indices
print("Class indices:", train_generator.class_indices)
print("Number of training samples:", train_generator.samples)
print("Number of validation samples:", validation_generator.samples)

# 4. VISUALIZE SAMPLE IMAGES
# ===============================
def plot_sample_images():
    plt.figure(figsize=(12, 8))
    sample_batch = next(train_generator)
    images, labels = sample_batch

    for i in range(8):
        plt.subplot(2, 4, i+1)
        plt.imshow(images[i])

        # Get class name from label
        class_idx = np.argmax(labels[i])
        class_names = list(train_generator.class_indices.keys())
        plt.title(f'Class: {class_names[class_idx]}')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

# Plot sample images
plot_sample_images()

# 5. BUILD VGG16 MODEL
# ===============================
# Load pretrained VGG16 model without top classification layers
base_model = VGG16(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

# Freeze the base model layers (transfer learning)
base_model.trainable = False

# Add custom classification head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(NUM_CLASSES, activation='softmax')(x)

# Create the complete model
model = Model(inputs=base_model.input, outputs=predictions)

# 6. COMPILE MODEL
# ===============================
model.compile(
    optimizer=Adam(learning_rate=LEARNING_RATE),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Display model summary
model.summary()

# 7. SETUP CALLBACKS
# ===============================
callbacks = [
    EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=3,
        min_lr=1e-7,
        verbose=1
    )
]

# ===============================
# 8. TRAIN THE MODEL
# ===============================
print("Starting training...")
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE,
    callbacks=callbacks,
    verbose=1
)

# ===============================
# 9. FINE-TUNING (OPTIONAL)
# ===============================
print("\nStarting fine-tuning...")

# Unfreeze the top layers of VGG16 for fine-tuning
base_model.trainable = True

# Fine-tune from this layer onwards
fine_tune_at = 100

# Freeze all layers before fine_tune_at
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

# Recompile with lower learning rate for fine-tuning
model.compile(
    optimizer=Adam(learning_rate=LEARNING_RATE/10),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Continue training with fine-tuning
fine_tune_epochs = 10
total_epochs = len(history.history['loss']) + fine_tune_epochs

history_fine = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=total_epochs,
    initial_epoch=len(history.history['loss']),
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // BATCH_SIZE,
    callbacks=callbacks,
    verbose=1
)

# 10. PLOT TRAINING HISTORY
# ===============================
def plot_training_history(history, history_fine=None):
    plt.figure(figsize=(15, 5))

    # Combine histories if fine-tuning was done
    if history_fine:
        acc = history.history['accuracy'] + history_fine.history['accuracy']
        val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']
        loss = history.history['loss'] + history_fine.history['loss']
        val_loss = history.history['val_loss'] + history_fine.history['val_loss']
        epochs_range = range(len(acc))
    else:
        acc = history.history['accuracy']
        val_acc = history.history['val_accuracy']
        loss = history.history['loss']
        val_loss = history.history['val_loss']
        epochs_range = range(len(acc))

    # Plot accuracy
    plt.subplot(1, 3, 1)
    plt.plot(epochs_range, acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Plot loss
    plt.subplot(1, 3, 2)
    plt.plot(epochs_range, loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot learning rate (if available)
    plt.subplot(1, 3, 3)
    if 'lr' in history.history:
        lr = history.history['lr']
        if history_fine and 'lr' in history_fine.history:
            lr = lr + history_fine.history['lr']
        plt.plot(epochs_range, lr)
        plt.title('Learning Rate')
        plt.xlabel('Epochs')
        plt.ylabel('Learning Rate')

    plt.tight_layout()
    plt.show()

# Plot training history
plot_training_history(history, history_fine)

# ===============================
# 11. EVALUATE MODEL
# ===============================
# Get predictions on validation set
validation_generator.reset()
predictions = model.predict(validation_generator, verbose=1)
predicted_classes = np.argmax(predictions, axis=1)

# Get true labels
true_classes = validation_generator.classes
class_labels = list(validation_generator.class_indices.keys())

# Classification report
print("\nClassification Report:")
print(classification_report(true_classes, predicted_classes, target_names=class_labels))

# Confusion Matrix
def plot_confusion_matrix(true_classes, predicted_classes, class_labels):
    cm = confusion_matrix(true_classes, predicted_classes)

    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_labels, yticklabels=class_labels)
    plt.title('Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

    # Calculate accuracy for each class
    for i, class_name in enumerate(class_labels):
        class_accuracy = cm[i, i] / np.sum(cm[i, :])
        print(f"{class_name} accuracy: {class_accuracy:.3f}")

plot_confusion_matrix(true_classes, predicted_classes, class_labels)

# ===============================
# 12. MAKE PREDICTIONS ON NEW IMAGES
# ===============================
def predict_single_image(image_path, model, class_labels):
    """Predict class for a single image"""
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMG_SIZE)
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) / 255.0

    prediction = model.predict(img_array, verbose=0)
    predicted_class_idx = np.argmax(prediction)
    predicted_class = class_labels[predicted_class_idx]
    confidence = prediction[0][predicted_class_idx]

    # Display results
    plt.figure(figsize=(8, 4))

    plt.subplot(1, 2, 1)
    plt.imshow(img)
    plt.title(f'Input Image')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.bar(class_labels, prediction[0])
    plt.title(f'Prediction: {predicted_class}\nConfidence: {confidence:.3f}')
    plt.ylabel('Probability')
    plt.xticks(rotation=45)

    plt.tight_layout()
    plt.show()

    return predicted_class, confidence

# Example usage (replace with actual image path):
# predicted_class, confidence = predict_single_image('/path/to/test/image.jpg', model, class_labels)

# ===============================
# 13. SAVE THE MODEL
# ===============================
# Save the entire model
model.save('/content/drive/MyDrive/vgg16_kidney_classification.h5')
print("Model saved successfully!")

# ===============================
# 14. MODEL PERFORMANCE SUMMARY
# ===============================
# Final evaluation
final_loss, final_accuracy = model.evaluate(validation_generator, verbose=0)
print(f"\nFinal Model Performance:")
print(f"Validation Loss: {final_loss:.4f}")
print(f"Validation Accuracy: {final_accuracy:.4f}")

print("\nProject completed successfully!")

